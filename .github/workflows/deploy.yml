name: Test API Prediction Sentiment

on:
  push:
    branches:
      - main
  pull_request:
    branches:
      - main

jobs:
  test:
    runs-on: windows-latest

    steps:
    # Étape 1 : Configuration de l'environnement
    - name: Check out repository
      uses: actions/checkout@v3

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: "3.12"

    # Étape 2 : Installer les dépendances
    - name: Install dependencies
      run: |
        python -m venv myenv
        .\myenv\Scripts\activate
        pip install --upgrade pip
        pip install -r requirements.txt

    # Étape 3 : Télécharger les données NLTK
    - name: Download NLTK Data
      run: |
        .\myenv\Scripts\activate
        python -m nltk.downloader punkt wordnet omw-1.4 stopwords
      env:
        NLTK_DATA: ${{ runner.temp }}/nltk_data

    # Vérification du téléchargement des ressources NLTK
    - name: Verify NLTK Data
      run: |
        .\myenv\Scripts\activate
        python -c "import nltk; print(nltk.data.find('tokenizers/punkt'))"

    # Étape 4 : Lancer l'API FastAPI sur le port 8080
    - name: Run FastAPI app
      run: |
        .\myenv\Scripts\activate
        start uvicorn API_prediction_sentiment:app --host 0.0.0.0 --port 8080 --reload
      env:
        NLTK_DATA: ${{ runner.temp }}/nltk_data

    # Étape 5 : Lancer les tests unitaires pour l'API
    - name: Run FastAPI tests
      run: |
        .\myenv\Scripts\activate
        pytest test_API_prediction_sentiment.py --disable-warnings

    # Étape 6 : Lancer l'application Streamlit
    - name: Run Streamlit app
      run: |
        .\myenv\Scripts\activate
        start streamlit run streamlit_dashboard_P7.py --server.port=8502
      env:
        STREAMLIT_SERVER_PORT: 8502

    # Étape 7 : Tester si l'application Streamlit est accessible
    - name: Test Streamlit app
      run: |
        sleep 10  # Attendre quelques secondes pour s'assurer que l'application démarre
        curl -f http://localhost:8502
